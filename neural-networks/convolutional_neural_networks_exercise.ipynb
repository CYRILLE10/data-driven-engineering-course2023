{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDQGK6Mx7kpP"
      },
      "source": [
        "## # Exercise on Convulotional Neural Networks \n",
        "\n",
        "In this exercise we will have a look at fully connected Convulotional Neural Networks (CNNs) for classification tasks such as computer vision.\n",
        "\n",
        "## Convolutional Neural Networks (CNNs)\n",
        "\n",
        "Convolutional Neural Networks (CNNs) are a type of deep neural network that are commonly used for image recognition, image classification, and computer vision tasks. CNNs are designed to take advantage of the spatial structure of input data, which is particularly relevant for image data.\n",
        "\n",
        "CNNs differ from other types of neural networks in that they treat their input data as a grid rather than a long vector of values. This grid-like structure is well-suited to image data, where the spatial relationships between pixels are important for understanding the visual content of the image.\n",
        "\n",
        "\n",
        "**Figure 1. ANN & CNN  [([Stanford, CS231n])](https://cs231n.github.io/convolutional-networks/)** \n",
        "\n",
        "![ANN_CNN](https://github.com/GerasimosG/images/blob/main/ann_cnn.png?raw=truee)\n",
        "\n",
        "\n",
        "\n",
        "A key component of CNNs are the convolutional layers. These layers are responsible for detecting features in the input data such as edges, lines, and color blobs. Each convolutional layer contains multiple filters, which are small squares of weights that slide over the input data and produce a feature map. The number of filters in a convolutional layer determines how many different features it can detect.\n",
        "\n",
        "Filters are also referred to as kernels and they are responsible for learning patterns and detecting edges, shapes, textures, or other salient features in the input image. During the convolution operation, the filter slides over the input image one pixel at a time, and calculates the dot product between the filter values and the corresponding pixel values in the input image. The resulting values form the output feature map, which highlights the locations of the detected features in the input image.\n",
        "\n",
        "The padding and stride are important hyperparameters in the convolutional layer. The padding size determines the number of zeros around the input image, and the stride specifies how many pixels the filter slides over the input image at a time.\n",
        "\n",
        "Pooling layers are another important component of CNNs. These layers downsample the feature maps produced by the convolutional layers to reduce the size of the data while retaining the most important information. The most common type of pooling layer is the max-pooling layer, which selects the maximum value within a rectangular region of the feature map and discards the rest. This reduces the size of the feature map while retaining the most salient features.\n",
        "\n",
        "The output of the last pooling layer is typically flattened into a vector and passed to a fully connected layer for classification. In this layer, each neuron is connected to every neuron in the previous layer, allowing for complex nonlinear relationships between the input data and the output classes.\n",
        "\n",
        "In summary, CNNs are a powerful type of neural network that are designed to take advantage of the spatial structure of input data, particularly image data. The convolutional layers detect features in the input data, while the pooling layers downsample the feature maps to reduce their size. The output of the last pooling layer is typically flattened and passed through one or more fully connected layers for classification or other downstream tasks.\n",
        "\n",
        "\n",
        "**Figure 2.LENET: A LeNET-5 Network [([LeCun, 1998])](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=726791&casa_token=3_NNxki4NZ4AAAAA:fww7n8pxscH835KHcECLMclXHlX7wdW7YqM4ARSPk6IVkB2-XLBv5Po-XXWQOFg_XK3JIqPo9TVY&tag=1)**\n",
        "\n",
        "\n",
        "![LENET](https://github.com/GerasimosG/images/blob/main/yanlecun.png?raw=true) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L71IB15Z7kpS"
      },
      "source": [
        "* Filters\n",
        "\n",
        "Filters are square-shaped objects that slide over an image to extract specific features, and their size is determined by a hyperparameter. During convolution, the filter slides over each image row to generate a feature map that highlights the presence of certain features. Each pixel in a convolutional layer has a weight learned during training, and the number of weights is determined by the filter size and the number of channels in the input. Increasing the number of filters increases the number of weights in the network, making it more complex and potentially more accurate.\n",
        "\n",
        "\n",
        "**Figure 3. Filters  [([Stanford, CS231n])](https://cs231n.github.io/convolutional-networks/)** \n",
        "\n",
        "![Filter](https://github.com/GerasimosG/images/blob/main/filters.png?raw=true)\n",
        "\n",
        "* Max Pooling\n",
        "\n",
        "Pooling layers are another important component of a convolutional neural network (CNN). Pooling layers are typically placed after convolutional layers and are used to reduce the spatial size (width and height) of the feature maps. The most common type of pooling is called max pooling, where the maximum value within a small rectangular window is selected and retained, while the other values are discarded. This process helps to reduce the number of parameters and computations required for subsequent layers, while also helping to prevent overfitting.\n",
        "\n",
        "\n",
        "**Figure 4. Max Pooling  [([Stanford, CS231n])](https://cs231n.github.io/convolutional-networks/)** \n",
        "\n",
        "![MPOOL](https://github.com/GerasimosG/images/blob/main/max_pool.png?raw=true)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6FC6WBA7kpT"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2TwS8Fh7kpU"
      },
      "outputs": [],
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "\n",
        "# Helper libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIQA1wNf7kpU"
      },
      "source": [
        "The CIFAR-10 dataset contains 60,000 color images of 32 x 32 pixels in 3 channels divided into 10 classes. Each class contains 6,000 images. The training set contains 50,000 images, while the test sets provides 10,000 images. This image taken from the CIFAR repository ( https://www.cs.toronto.edu/~kriz/cifar.html ). This is a classification problem with 10 classes(muti-label classification). We can take a view on this image for more comprehension of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tl0dTpqu7kpU"
      },
      "outputs": [],
      "source": [
        "# The classes are:\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "                'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# You can access the CIFAR10 directly from TensorFlow\n",
        "cifar10 = tf.keras.datasets.cifar10\n",
        "\n",
        "# Load the data\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "print(f'train_images shape:{train_images.shape}')\n",
        "print(f'train_labels shape:{train_labels.shape}')\n",
        "print(f'test_images shape:{test_images.shape}')\n",
        "print(f'test_labels shape:{test_labels.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5tHChej7kpV"
      },
      "outputs": [],
      "source": [
        "# First, we can visualize the CIFAR10 data\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i])\n",
        "    plt.xlabel(class_names[train_labels[i][0]])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEOBsm7l7kpV"
      },
      "outputs": [],
      "source": [
        "# Now we create a cat_vs_dog dataset from Cifar10\n",
        "class_names = ['cat', 'dog']\n",
        "\n",
        "# Get from CIFAR10 the indexes for cats and dogs\n",
        "idx_cats = np.argwhere(train_labels[:,0] == 3)\n",
        "idx_dogs = np.argwhere(train_labels[:,0] == 5)\n",
        "\n",
        "# Create the new dataset and change the labels: 1 for dogs and 0 for cats\n",
        "# If you have kernel problems, reduce the training size\n",
        "train_size = 5000\n",
        "\n",
        "train_images_cats_dogs = np.zeros((train_size,32,32,3), dtype='uint8')\n",
        "train_labels_cats_dogs = np.zeros((train_size,1),dtype='int')\n",
        "\n",
        "train_images_cats_dogs[:train_size//2] = train_images[idx_cats[:train_size//2,0]]\n",
        "train_images_cats_dogs[train_size//2:train_size] = train_images[idx_dogs[:train_size//2,0]]\n",
        "\n",
        "train_labels_cats_dogs[:train_size//2] = tf.zeros_like(idx_cats[:train_size//2])\n",
        "train_labels_cats_dogs[train_size//2:train_size] = tf.ones_like(idx_cats[:train_size//2])\n",
        "\n",
        "train_images_cats_dogs = tf.convert_to_tensor(train_images_cats_dogs)\n",
        "\n",
        "# Shuffle the train data before train\n",
        "indices = tf.range(start=0, limit=tf.shape(train_images_cats_dogs)[0], dtype=tf.int32)\n",
        "shuffled_indices = tf.random.shuffle(indices)\n",
        "\n",
        "train_images_cats_dogs = tf.gather(train_images_cats_dogs, shuffled_indices)\n",
        "train_labels_cats_dogs = tf.gather(train_labels_cats_dogs, shuffled_indices)\n",
        "\n",
        "# We do the same for test dataset\n",
        "idt_cats = np.argwhere(test_labels[:,0] == 3)\n",
        "idt_dogs = np.argwhere(test_labels[:,0] == 5)\n",
        "\n",
        "# If you have kernel problems, reduce the test size\n",
        "test_size = 1000\n",
        "\n",
        "test_images_cats_dogs = np.zeros((test_size,32,32,3), dtype='uint8')\n",
        "test_labels_cats_dogs = np.zeros((test_size,1),dtype='int')\n",
        "\n",
        "test_images_cats_dogs[:test_size//2] = test_images[idt_cats[:test_size//2,0]]\n",
        "test_images_cats_dogs[test_size//2:test_size] = test_images[idt_dogs[:test_size//2,0]]\n",
        "\n",
        "test_labels_cats_dogs[:test_size//2] = tf.zeros_like(idt_cats[:test_size//2])\n",
        "test_labels_cats_dogs[test_size//2:test_size] = tf.ones_like(idt_cats[:test_size//2])\n",
        "\n",
        "test_images_cats_dogs = tf.convert_to_tensor(test_images_cats_dogs)\n",
        "\n",
        "# Shuffle the test data\n",
        "indices = tf.range(start=0, limit=tf.shape(test_images_cats_dogs)[0], dtype=tf.int32)\n",
        "shuffled_indices = tf.random.shuffle(indices)\n",
        "\n",
        "test_images_cats_dogs = tf.gather(test_images_cats_dogs, shuffled_indices)\n",
        "test_labels_cats_dogs = tf.gather(test_labels_cats_dogs, shuffled_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ke4eFfzI7kpV"
      },
      "outputs": [],
      "source": [
        "# Plot some pictures\n",
        "\n",
        "# plt.figure(figsize=(10,10))\n",
        "# for i in range(25):\n",
        "#     plt.subplot(5,5,i+1)\n",
        "#     plt.xticks([])\n",
        "#     plt.yticks([])\n",
        "#     plt.grid(False)\n",
        "#     plt.imshow(train_images_cats_dogs[i])\n",
        "#     plt.xlabel(class_names[train_labels_cats_dogs[i][0]])\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cT29Br17kpW"
      },
      "outputs": [],
      "source": [
        "# Models generally run better on normalized values. The best way to normalize the data depends on each individual dataset. \n",
        "# For the CIFAR10 dataset, we want each value to be between 0.0 and 1.0. \n",
        "# As all values originally fall under the 0.0-255.0 range, divide by 255.0.\n",
        "\n",
        "train_images_cats_dogs = train_images_cats_dogs / 255\n",
        "test_images_cats_dogs = test_images_cats_dogs / 255\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hvkpwnsi7kpW"
      },
      "outputs": [],
      "source": [
        "#Convolutional neural networks\n",
        "\n",
        "# model = tf.keras.Sequential()\n",
        "\n",
        "# model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "# model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "# model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "# model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "# model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "# model.add(tf.keras.layers.Flatten())\n",
        "# model.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
        "# model.add(tf.keras.layers.Dense(units=16, activation='relu'))\n",
        "# model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
        "\n",
        "\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPLI26cW7kpW"
      },
      "outputs": [],
      "source": [
        "# model.compile(  optimizer='adam',\n",
        "#                 loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), ## Since we use softmax\n",
        "#                 metrics=['accuracy']) ## We can use accuracy as metric\n",
        "\n",
        "# history = model.fit(train_images_cats_dogs, train_labels_cats_dogs, \n",
        "#                     epochs=20, \n",
        "#                     validation_data=(test_images_cats_dogs, test_labels_cats_dogs))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TIP:** Go to Runtime -> Change Runtime Type -> Hardware Accelerator -> GPU\n",
        "\n",
        "Rerun the previous cell and see the difference in training time."
      ],
      "metadata": {
        "id": "JAR_Zxagn9mU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3oYPCMo7kpW"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "\n",
        "# plt.figure(figsize=(7,7))\n",
        "# plt.plot(history.history['accuracy'], label='accuracy')\n",
        "# plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.legend(loc='lower right')\n",
        "\n",
        "# test_loss, test_acc = model.evaluate(test_images_cats_dogs,  test_labels_cats_dogs, verbose=2)\n",
        "\n",
        "# print(f'Test loss: {test_loss}')\n",
        "# print(f'Test accuracy: {test_acc}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qMTfB5M7kpW"
      },
      "outputs": [],
      "source": [
        "# Useful functions to plot the results\n",
        "\n",
        "# def plot_image(i, predictions_array, true_label, img):\n",
        "#   true_label, img = true_label[i][0], img[i]\n",
        "#   plt.grid(False)\n",
        "#   plt.xticks([])\n",
        "#   plt.yticks([])\n",
        "\n",
        "#   plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "#   predicted_label = np.argmax(predictions_array)\n",
        "#   if predicted_label == true_label:\n",
        "#     color = 'blue'\n",
        "#   else:\n",
        "#     color = 'red'\n",
        "\n",
        "#   plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "#                                 100*np.max(predictions_array),\n",
        "#                                 class_names[true_label]),\n",
        "#                                 color=color)\n",
        "\n",
        "# def plot_value_array(i, predictions_array, true_label):\n",
        "#   true_label = true_label[i][0]\n",
        "#   plt.grid(False)\n",
        "#   plt.xticks(range(len(class_names)))\n",
        "#   plt.yticks([])\n",
        "#   thisplot = plt.bar(range(len(class_names)), predictions_array, color=\"#777777\")\n",
        "#   plt.ylim([0, 1])\n",
        "#   predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "#   thisplot[predicted_label].set_color('red')\n",
        "#   thisplot[true_label].set_color('blue')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHpHjuY57kpX"
      },
      "outputs": [],
      "source": [
        "# predictions = model.predict(test_images_cats_dogs)\n",
        "\n",
        "# num_rows = 5\n",
        "# num_cols = 3\n",
        "# num_images = num_rows*num_cols\n",
        "# plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "# for i in range(num_images):\n",
        "#   plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "#   plot_image(i, predictions[i], test_labels_cats_dogs, test_images_cats_dogs)\n",
        "#   plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "#   plot_value_array(i, predictions[i], test_labels_cats_dogs)\n",
        "#   #plt.title(\"True: %s \\nPredict: %s\" % (test_labels_cats_dogs[i], test_labels_cats_dogs[predictions[i]]))\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ER215PkR7kpX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT9wAIiY7kpX"
      },
      "source": [
        "**To Do:**\n",
        "\n",
        "Now we will try a more complex classification task. We will try to classify all 10 classes from the Cifar10 dataset. \n",
        "Your task is to create a CNN model, train it and evaluate the accuracy.\n",
        "Try to tune the hyperparameters of the CNN model and (number of layers, number of filters, parameters of the optimiser etc)\n",
        "\n",
        "TIP: Search in the [documentation](https://keras.io/) for changing the architecture of the neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nW0RjEs7kpX"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W33Pthoz7kpX"
      },
      "outputs": [],
      "source": [
        "## Load the data as the previous example\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "# (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "# print('x_train shape:', x_train.shape)\n",
        "# print('y_train shape:', y_train.shape)\n",
        "# print()\n",
        "# print(x_train.shape[0], 'train samples')\n",
        "# print(x_test.shape[0], 'test samples')\n",
        "# print()\n",
        "\n",
        "# img_width, img_height, img_num_channels = x_train.shape[1], x_train.shape[2], x_train.shape[3]\n",
        "\n",
        "# input_shape = (img_width, img_height, img_num_channels)   ## Input shape\n",
        "\n",
        "# print(f'Image width: {img_width}, Image height: {img_height}, Number of channels: {img_num_channels}')\n",
        "# print(f'Thus -> Input shape:{input_shape}')\n",
        "\n",
        "# # Normalize the data. Before we need to connvert data type to float for computation.\n",
        "# x_train = x_train.astype('float32')\n",
        "# x_test = x_test.astype('float32')\n",
        "# x_train /= 255\n",
        "# x_test /= 255\n",
        "\n",
        "# num_classes = 10 ## We'll try to classify all 10 classes of the dataset\n",
        "\n",
        "# class_names = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
        "\n",
        "# # Convert class vectors to binary class matrices. This is called one-hot encoding.\n",
        "# y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "# y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "# print()\n",
        "# print(f'x_train shape: {x_train.shape}, y_train shape: {y_train.shape}, x_test shape: {x_test.shape}, y_test shape: {y_test.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Zh9-vRD7kpX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFbppmR37kpX"
      },
      "outputs": [],
      "source": [
        "# Create the model\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "# TIP: try the architecture below\n",
        "# CONV => RELU => CONV => RELU => POOL => DROPOUT\n",
        "\n",
        "#  What is dropout? Dropout is a regularization technique for reducing overfitting in neural networks by preventing complex co-adaptations on training data.\n",
        "#  It is a form of regularization, where a proportion of nodes in the layer are randomly ignored (setting their weights to zero) for each training sample.\n",
        "#  This has the effect of making the layer look for distributed features in its input, which improves generalization.\n",
        "\n",
        "# CONV => RELU => CONV => RELU => POOL => DROPOUT\n",
        "## MaxPooling every other layer\n",
        "\n",
        "\n",
        "# FLATTERN => DENSE => RELU => DROPOUT\n",
        "\n",
        "# add a softmax activation on the last Dense layer\n",
        "\n",
        "# Check your architecture !\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVg_iL0F7kpY"
      },
      "outputs": [],
      "source": [
        "# Let's train the model \n",
        "# model.compile ...."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHMoqRXC7kpY"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "# def plotmodelhistory(history): \n",
        "#     fig, axs = plt.subplots(1,2,figsize=(15,5)) \n",
        "#     # summarize history for accuracy\n",
        "#     axs[0].plot(history.history['accuracy']) \n",
        "#     axs[0].plot(history.history['val_accuracy']) \n",
        "#     axs[0].set_title('Model Accuracy')\n",
        "#     axs[0].set_ylabel('Accuracy') \n",
        "#     axs[0].set_xlabel('Epoch')\n",
        "#     axs[0].legend(['train', 'validate'], loc='upper left')\n",
        "#     # summarize history for loss\n",
        "#     axs[1].plot(history.history['loss']) \n",
        "#     axs[1].plot(history.history['val_loss']) \n",
        "#     axs[1].set_title('Model Loss')\n",
        "#     axs[1].set_ylabel('Loss') \n",
        "#     axs[1].set_xlabel('Epoch')\n",
        "#     axs[1].legend(['train', 'validate'], loc='upper left')\n",
        "#     plt.show()\n",
        "\n",
        "# # list all data in history\n",
        "# print(history.history.keys())\n",
        "\n",
        "# plotmodelhistory(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLUhXJyQ7kpb"
      },
      "outputs": [],
      "source": [
        "# Score trained model.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make prediction on the test set.\n",
        "\n",
        "# Convert predictions classes to one hot vectors \n",
        "# y_pred_classes = np.argmax(pred, axis=1) \n",
        "\n",
        "# Convert validation observations to one hot vectors\n",
        "# y_true = np.argmax(y_test, axis=1)"
      ],
      "metadata": {
        "id": "KCum64xviN-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVh0rK8F7kpb"
      },
      "outputs": [],
      "source": [
        "## Check the predicted labels against the true labels\n",
        "\n",
        "# num_rows = 5\n",
        "# num_cols = 5\n",
        "# fig, axes = plt.subplots(num_rows, num_cols, figsize=(12,12))\n",
        "# axes = axes.ravel()\n",
        "\n",
        "# for i in np.arange(0, num_rows*num_cols):\n",
        "#     axes[i].imshow(x_test[i])\n",
        "#     axes[i].set_title(f\"True: {class_names[y_true[i]]} \\nPredict: {class_names[y_pred_classes[i]]}\")\n",
        "#     axes[i].axis('off')\n",
        "#     plt.subplots_adjust(wspace=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resources**\n",
        "\n",
        "\n",
        "\n",
        "*   TensorFlow [guide](https://www.tensorflow.org/guide)\n",
        "*   Stanford's [Course](https://cs231n.github.io/convolutional-networks/) for CNNs\n",
        "* Professor Jeff Heaton's github [page](https://github.com/huisai/jeffheaton-t81_558_deep_learning) for Deep Learning\n",
        "* Deep Learning Tuning [Playbook](https://github.com/google-research/tuning_playbook) from Google\n",
        "\n"
      ],
      "metadata": {
        "id": "yGbIKsf4qfTs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahUVK-D57kpb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}